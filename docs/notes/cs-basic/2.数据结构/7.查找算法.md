---
title: 查找算法
createTime: 2025/05/16 21:44:59
permalink: /cs-basic/ds/search-algo/
icon: 'bx:search-alt'
---

> [!NOTE]
> 为了方便算法代码的书写，以下所有代码都是以int类型举例，重要的是算法的思想和性质。


## **什么是查找**

> 查找：在数据集合中寻找满足某种条件的数据元素的过程称为查找。

查找的结果只能有两种，分别为**查找成功**和**查找失败**，前者表示在查找表中寻找到了满足条件的元素，后者表示没有在查找表中寻找到满足条件的元素。
这里出现的**查找表**是用于查找的数据集合，其由同一类型的元素组成。

查找表有两种分类分别为：

- 静态查找表：对查找表只有查找操作，不存在修改元素的操作
- 动态查找表：对查找表有动态地插入和删除

静态查找容易理解，只存在查找操作而已，常见的**静态查找算法**有：折半查找、顺序查找、散列查找；动态查找值得说明一下，随着时间的流逝，数据集合中的数据会改变，
因为动态查找提供了除查找操作外的插入、删除操作，为了保持查找的高效性，常见的**动态查找算法**有：二叉排序树的查找、散列查找。

我们查找是根据**关键字**来进行查找的，那什么是关键字呢？就是用于查找的“标志”，其必然是**唯一**的，比如要以学生的学号将班上的学生进行排序，这里的学号就是关键字。

评判查找算法效率的重要指标是什么，我们怎样知道该查找算法好不好呢？这个指标就是**平均查找长度(ASL)**。顾名思义，就是查找到目标元素需要查找的平均次数。

::: info 注意
比较次数通常指的是**数据元素与目标值进行比较的次数**。
:::

$$ASL=\sum_{i=1}^nP_iC_i$$

**$P_i$是查找元素i的概率，$C_i$是查找元素i的比较次数，ASL是一个查找算法不能不谈的重要性质**。

## **顺序查找和折半查找**

这两个算法是最“耿直”的查找算法了，十分易懂和直接。

---

### **顺序查找**

顺序查找，显然说的是从一端到另一端依次查找，只要有目标元素就查找成功了，故顺序表和链表都可以使用该算法。

但是该线性表中的元素可能是有序的，也有可能是无序的，这两者的ASL是不同的，接下来一一说明。

==一般线性表的顺序查找==

为什么说是一般呢，这是因为不论是有序和无序都可以使用这个算法，但一般是给无序线性表使用的，因为有序线性表有自己更优秀的算法！

::: demo-wrapper no-padding title="一般线性表的顺序查找算法"
```c
int normal_search(int arr[], int len, int goal){
    for (int i = 0; i < len; i++) {
        if (arr[i] == goal) {
            return i;
        }
    }
    return -1;
}
```
:::

在这里还可以进行优化，使用**哨兵模式**，可以将内部的if判断条件全部省去！

原理是将目标元素放在线性表索引为0的位置上，然后从最后一个元素向前遍历，通过在for循环中的判断`arr[i]!=goal`（和上述的`i < len`一样的原理，
在for循环中`i++`一次就会判断是否还小于len），遍历的元素是否为目标元素，其一定能在arr中遍历到goal，最后返回对应的索引，不过线性表中不存在时返回的是0。

---

对于一般线性表顺序查找的ASL分析，假设有n个元素，且每个元素的查找概率相同：

$$ASL_{查找成功}=\sum_{i=0}^{n-1}\frac{1}{n}(i+1)=\frac{n+1}{2}$$

$$ASL_{查找失败}=n$$

由上述的ASL表达式可知，ASL与n呈线性相关，在n很大时，顺序查找的效率很低，但其对元素的存储和有序性没有任何要求。需要注意的是**链表只能进行顺序查找**！

==有序线性表的顺序查找==

不难想到，如果线性表中的元素有序的话，在查找失败时就可直接返回，后续剩余元素的比较都不用进行，降低了查找失败的ASL。

什么时候是失败呢？如果线性表关键字按从小到大排序，查找值为`goal`，若`i`位置元素小于`goal`，且`i+1`位置大于`goal`，则失败了。因为`i+1`位置上的元素都大于`goal`了，此后的元素必定也大于`goal`。

::: demo-wrapper no-padding title="有序线性表的顺序查找算法"
```c
int order_search_linear(int arr[], int len, int goal) {
    for (int i = 0; i < len; i++) {
        if (arr[i] == goal) {
            return i;
        } else if (arr[i] > goal) {
            return -1;
        }
    }
    return -1;
}
```
:::

每次判断都有三种可能，等于`goal`，大于`goal`，小于`goal`，等于的话就是查找成功，否则继续判断，这样可以将其抽象为一颗**二叉树**，该二叉树称为**判定树**。

![有序线性表查找的判定树](https://raw.githubusercontent.com/amatureemoprince/java-cofe-pictures/master/1743515983653-08346e79-982b-42d5-8eea-1ecca15f956b.jpeg)

矩形结点是**虚拟**的，也可以称为**失败结点**！

---

可知有序的线性表对应的查找成功ASL与一般的类似，不成功ASL更好一些：

$$ASL_{查找成功}=\frac{n+1}{2}$$

$$ASL_{查找不成功}=\frac{1+2+3+...+n+n}{n+1}=\frac{n}{2} + \frac{n}{n+1}$$

---

### **折半查找**

折半查找需要利用**有序**和**随机存取**特性，故只能用于**顺序存储结构**的线性表！

通过不断缩小目的元素所在的区间，直到找到或达到结束条件为止。比如从1-5中查找2，首先对比1-5中间的元素，显然3大于2，故2只能在1-3之间，依次类推从而找到2。

::: demo-wrapper no-padding title="折半查找算法"
```c
int binary_search(int arr[], int len, int goal){
    int low = 0;
    int high = len - 1;
    int mid;
    while(low <= high){
        mid = (high - low) / 2 + low;
        if(arr[mid] == goal){
            return mid;
        }
        else if (arr[mid] > goal){
            high = mid - 1;
        }
        else if (arr[mid] < goal){
            low = low + 1;
        }
    }
    return -1;
}
```
:::

每次比较都是比较的区间中间元素，故可以将折半查找的判定树抽象为一颗**平衡二叉树**，任意一个结点的子树高度相差不会超过1。

![折半查找判定树](https://raw.githubusercontent.com/amatureemoprince/java-cofe-pictures/master/查找树.png)

---

因为整体呈树形，其查找的时间复杂度显然为$O(log_2\,n)$

其对应的ASL为：

$$ASL_{查找成功}=\frac{1}{n}(1×1+2×2+...+h×2^{h-1})=\frac{n+1}{n}log_2(n+1)-1\approx log_2(n+1)-1$$

查找失败时的ASL根据之前比较的次数之和再除以整体的失败结点个数，上图的计算失败ASL如下：

$$ASL_{查找失败}=\frac{2×1+3×6}{7}=\frac{20}{7}$$

要查找在区间$(11,14)$的失败结点，首先得比较上面的16、11、14，故比较次数为3，同一层的失败结点有6个，故为3×6，式子分子上的2×1类似！

---

### **分块查找**

有没有办法将上面的算法综合一下呢？答案是有的，也就是**分块算法**。

通过一个索引数据结构快速找到对应区间，再从区间中查找目标元素，这就是该算法的基本思想。其和查字典的思想类似，先定位，再查找。

因为查找表中的元素被分为多个区间，且可以用区间内最大元素构造索引表，故区间之间元素需要有序（前一个区间内的最大值小于后一个区间的最小值），区间内元素无所谓。

用区间内最大元素构成索引表，若要查找的元素小于索引表中元素时，就从查找表对应的索引处开始查找元素。

![分块查找示意图](https://raw.githubusercontent.com/amatureemoprince/java-cofe-pictures/master/查找算法.png)

如：要查找上图13元素，先从索引表中确定13小于16，其索引值为3，所以从查找表索引3开始查找，找到13结束。

---

显然，查找算法的ASL为查找索引表的ASL加上查找查找表的ASL。设：长度为n的查找表均匀分为b块，每块有s个记录，在等概率的条件下，在块内和索引表中都采用顺序查找，则：

$$ASL_{查找成功}=\frac{s+1}{2} + \frac{b+1}{2}$$

$$ASL_{查找失败}=\frac{b}{2}+s$$

在查找成功的情况下，若$s=\sqrt n$，则平均查找成功长度有最小值$\sqrt n + 1$，通过基本不等式可轻松得出。

虽然分块查找使用额外的存储空间存储索引表，查找索引表也增加了一定开销，但这样带来的提升也是不小的，更普遍的情况是带来性能的提升大于开销。这也是环绕计算机的一个核心优化手段——**空间换时间**！

因为需要快速定位到查找表中的位置，所以需要**随机存取**特性，故此算法只适用于**顺序存储结构**。

## **树形查找**

为什么会出现**树形查找**呢？我们知道保持一颗优秀的二叉树可以使查找效率很高，因为此时无论是插入、查找、删除，其时间复杂度都为$O(log_2n)$。

这里引入的树形查找就是为了构造并保持这种优秀的二叉树结构！其最基本的结构就是**二叉排序树**，在二叉排序树之后的所有的树形查找都是在此基础上添加了部分限制形成的。

因为树形查找是一种动态查找，故在此还需讨论结点的插入与删除操作。

---

### **二叉排序树（BST）**

> 定义：是一颗空树，或者满足下列性质的**二叉树**：
> - 若左子树非空，则左子树上所有结点的值均小于根结点的值
> - 若右子树非空，则右子树上所有结点的值均大于根结点的值
> - 左右子树也分别为一颗二叉树

意思就是**左小右大**，根据这个性质可知根结点为中间值，且用中序遍历二叉排序树可以得到一个递增的有序序列。

---

==BST的查找==

根据性质不难得出，查询从根结点开始，若根结点不为空，则用其值与目标元素比较，若相等，则查找成功；若小于，则查找右子树；否则，则查找左子树，其余结点与根结点操作类似。

显然可知，此操作为一个递归操作！

::: demo-wrapper no-padding title="BST的递归查找算法"
```c
/*
 * 传入BST的根结点和目的元素
 */
int recursion_search(bst_tree_node *tree, int goal){
    if(tree == NULL){
        return 0;
    }
    if(tree->data == goal){
        return 1;
    }
    else if(tree->data < goal){
        return recursion_search(tree->right, goal);
    }
    else{
        return recursion_search(tree->left, goal);
    }
}
```
:::

---

==BST的插入==

对于动态查找表，可以进行插入操作，因为插入后仍需保持原本的性质，所以需要在查找失败后进行插入，若BST中本来就有要插入的元素，则什么操作都不会执行。

由上述可知，插入的位置一定是在最后一个失败结点的左或右孩子位置。

::: demo-wrapper no-padding title="BST的插入算法"
```c
```
:::

---

==BST的删除==

对于BST的删除也要注意不能破坏其性质，其可以分为3种情况！

1. 删除的结点为叶子结点，显然删除后没有任何影响，直接删除则可（轻如鸿毛）；

2. 删除的结点有一颗子树，删除后，只需要用其子树的根结点替代被删除的结点则可（父债子偿）；

3. 删除的结点有两颗子树，删除后，只需要用直接后继或者直接前驱替代该结点则可，然后就转换为了前两种情况（斗转星移）。

这三种情况十分容易理解，故不再赘述。

---

BST的条件是最宽松的，以至于可能导致其退化为**链表**，导致$ASL_{查找成功}=\frac{n+1}{2}$，也有可能是十分理想的情况，左右子树高度相差不超过1，也就是平衡二叉树，
其$ASL$与树高$O(log_n)$成正比。

BST的ASL计算是得根据具体的BST形状用ASL计算公式计算的。

BST和折半查找类似，平均时间性能也差不多，但BST的形状会因为关键字的插入顺序不同而不同，折半查找不会，其判定树是唯一的。而且BST是一种动态查找表，折半查找是静态的，
所以BST的插入、删除操作十分容易实现，时间复杂度为$O(log_2n)$，若折半查找也存在插入、删除操作，时间复杂度就为$O(n)$，因为其“牵一发要动全身”。

---

### **平衡二叉树（AVL）**

上面的BST条件太宽松了，所以会导致退化到链表，若在BST性质的基础上再加上一些限制条件，则就可以避免这种退化现象的发生，故引出**平衡二叉树的定义**

> 在二叉树的定义基础上再添加一条：任意结点的左、右子树高度差的绝对值不超过1，这个绝对值称为**平衡因子**。

AVL的本质仍是一颗BST！

![AVL示意图](https://raw.githubusercontent.com/amatureemoprince/java-cofe-pictures/master/AVL.png)

上图结点中的值为该结点的平衡因子。

---

==AVL的插入==

和BST类似，首先也得找到最后一个失败结点，然后插入到其左或右孩子结点上，但这时候就不能直接“跑路”了，还需要确保其仍是一颗AVL，若不是了，则要经过一系列操作让其变为一颗AVL，操作的对象为**最小不平衡子树**，
也就是让从插入结点位置向上找到的第一个平衡因子大于1的结点作为最小不平衡子树的根结点。

若添加后仍是AVL就好办，不需要任何操作，但若不是AVL了，就有4种情况，分为对应着4种操作：

操作的最小不平衡子树的根结点为 A。

- RR（左单旋操作）：新结点在 A 的右孩子的右子树上插入，A 的右孩子为 B，则需要将 B 代替 A 作为根结点，A 作为 B 的左孩子，B 原本的左子树作为 A 的右子树
- LL（右单旋操作）：新结点在 A 的左孩子的左子树上插入，A 的左孩子为 B，则需要将 B 代替 A 作为根节点，A 作为 B 的右孩子，B 原本的右子树作为 A 的左子树
- RL（右左双旋操作）：新结点在 A 的右孩子的左子树上插入，A 的右孩子为 B，B 的左子树的根结点为 C，则需要先将 C 进行右旋操作，让 C 代替 B 的位置，然后再对 C 进行左旋操作，代替 A 的位置
- LR（左右双旋操作）：新结点在 A 的左孩子的右子树上插入，A 的左孩子为 B，B 的右子树的根结点为 C，则需要先将 C 进行左旋操作，让 C 代替 B 的位置，然后再对 C 进行右旋操作，代替 A 的位置

因为AVL的旋转操作较为简单，故单旋和多旋各举一个例子。

![AVL插入示意图](https://raw.githubusercontent.com/amatureemoprince/java-cofe-pictures/master/屏幕截图1.png)

---

==AVL的删除==

删除过程的前半部分和BST的删除完全一样，后半部分调整和AVL的插入调整类似。

首先先删除目的元素，删除后和插入一样，可能导致不再满足AVL的性质，若为不满足AVL性质的情况，则需要进行旋转操作。

从删除结点`w`位置往上找，一个平衡因子大于1的结点作为最小不平衡子树的根结点`z`，`y`为`z`的最高子树根结点，`x`为`y`的最高子树根结点，
接下来就和AVL插入操作后的调整一样了，看`x`在`z`的什么位置，就对应什么操作，这里就不再赘述了，需要注意的一点是**旋转操作会传播**，调整后可能又会破坏AVL的性质，
所以可能又会调整，甚至调整至根结点，导致树高减一。

---

==AVL的查找==

和BST的查找完全一样，只不过AVL不会出现BST那样的**极端情况（退化为链表）**，查找效率比BST好，为$O(log_2n)，$除此之外，AVL还多出了一些性质：

设$n_h$为深度为`h`的AVL中含有的**最少结点数**

则有$n_0=0,n_1=1,n_2=2,n_3=4,...,n_h=n_{h-2}+n_{n-1}+1$。

使用该结论，可以很快得出高为`h`的AVL含有**最少**的结点数为多少，还可以得出含有结点数为`n`的AVL高**最大**为多少。

---

### **红黑树（RBT）**

在 AVL 中插入或者删除一个结点后，会频繁地调整全树整体的拓扑结构，这样的代价是很大的，究其原因还是条件太过严格，故为了减小消耗，引入条件稍微宽松的红黑树。

> RBT：可以是一颗空树或者满足以下条件的**二叉树**：
> - 每颗结点要么是红色的，要么是黑色的 
> - 根节点是黑色的 
> - 叶结点（虚构的外部结点，NULL 结点） 都是黑色的
> - 不存在两个相邻的红结点 
> - 满足 BST 结点值的关系 
> - 每个结点到任意叶子结点的简单路径上，所含有的黑色结点数相同

引入虚拟结点的原因是为了**保证内部结点左右孩子不为空**。

---

红黑树有个 **黑高（bh）** 属性。

> 黑高定义：从某结点出发（不包含该结点）到达一个叶子结点的任意一个简单路径上的黑色结点个数。

![红黑树示意图](https://raw.githubusercontent.com/amatureemoprince/java-cofe-pictures/master/18f043ad71a2462ab52647c7b371456d.png)

根据RBT的定义，可以得出一些好用的结论：

1. **从根到叶结点的最长路径不大于最短路径的2倍**
2. **有n个内部结点的RBT的高度 $h\le 2log_2(n+1)$**
3. **RBT插入的结点初始为红色**

分析：

- 第一个结论：在最短时，路径上的所有结点都为黑色，而最长时，是红黑相间的，故最长的路径不会超过最短的路径 2 倍
- 第二个结论：因为在 $bh = h_b$ 时，RBT 的最少内部结点数 $n=2^{h_b}-1$ 个，又因为 RBT 的 $h\le2h_b$，故在 RBT 的内部结点树高为 $h$ 时有：$n \ge 2^{\frac{h}{2}} - 1$，化简后可得
- 第三个结论：插入时着红色更为方便，若父结点为黑色就不用进行额外的操作，但插入的结点若初始着为黑色，则不管怎样都会破坏RBT的性质

---

==RBT的插入==

仍然是需要找到要插入的位置，插入后结点初始为红色，若父结点为黑色，显然还保持着RBT的性质，直接结束，若父结点为红色，则需要通过旋转+变色进行调整，使其满足RBT的性质。

具体怎样操作呢？插入位置若为根结点则直接插入并将插入结点再次染色为黑色则可；若插入结点位置的父结点为黑色，仍保持RBT性质，直接结束；若插入结点位置的父结点为红色，则要看插入结点的**叔结点**，根据叔结点的颜色又将该情况分为两类：

1. 叔结点为黑色：
2. 叔结点为红色：

---

==RBT的删除==


## **B树和B+树**

对于B树和B+树，重点掌握B树，B+是B树的一种变体，它们都是**专门为优化磁盘或其他外部存储设备操作而设计**的数据结构。

---

### **B树及其基本操作**

使用场景：

- 文件系统： 早期的一些文件系统（如 NTFS）中，B 树被用于文件索引，但现代文件系统更多地倾向于 B+ 树
- MongoDB 的索引： NoSQL 数据库 MongoDB 的默认索引就是 B 树结构。由于 MongoDB 是文档型数据库，其索引可能需要支持更灵活的数据结构，B 树在这种场景下有其优势。当查询单个确切的值且数据可能在任何层级时，B 树理论上可能比 B+ 树少一次 I/O（如果数据恰好在内部节点被找到）

![B树示意图](https://raw.githubusercontent.com/amatureemoprince/java-cofe-pictures/master/2.png)

---

### **B+树及其基本操作**

使用场景：

- 关系型数据库索引： 这是 B+ 树最主要、最广泛的应用场景。几乎所有的关系型数据库（如 MySQL 的 InnoDB 存储引擎、Oracle、SQL Server 等）都使用 B+ 树作为其底层索引结构。这是因为数据库查询中频繁涉及：
**精确查找**： WHERE id = 123；
**范围查找**： WHERE price BETWEEN 100 AND 200，WHERE name LIKE 'A%'；
**排序**： ORDER BY column；
**全表扫描**： 在某些情况下，通过遍历叶子节点链表比其他方式更高效；
- 文件系统： 许多现代文件系统（如 Linux 的 Ext4、ReiserFS 等）也广泛使用 B+ 树来组织文件和目录的索引。这是因为文件系统也需要高效地查找文件、遍历目录内容和进行范围操作（比如查找某个日期范围内的文件）

![B+树示意图](https://raw.githubusercontent.com/amatureemoprince/java-cofe-pictures/master/3.png)

## **散列表**

### **散列表的基本概念**
---

### **散列函数的构造方法**
---

### **处理冲突的方法**
---

### **散列查找及性能分析的应用**
---